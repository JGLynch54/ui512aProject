Microsoft (R) Macro Assembler (x64) Version 14.43.34809.0   03/15/25 21:30:36
ui512a.asm						     Page 1 - 1


				;
				;			ui512a
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			File:			ui512a.asm
				;			Author:			John G. Lynch
				;			Legal:			Copyright @2024, per MIT License below
				;			Date:			May 13, 2024
				;
				;			Notes:
				;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
				;
				;				ui512a provides basic operations: zero, copy, compare, add, subtract.
				;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
				;               ui512md provides multiply and divide.
				;
				;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
				;				(currently using VS Community 2022 17.9.6)
				;
				;				It provides external signatures that allow linkage to C and C++ programs,
				;				where a shell/wrapper could encapsulate the methods as part of an object.
				;
				;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
				;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
				;
				;				If processor extensions are used, the caller must align the variables declared and passed
				;				on the appropriate byte boundary (e.g. alignas 64 for 512)
				;
				;				This module is very light-weight (less than 1K bytes) and relatively fast,
				;				but is not intended for all processor types or all environments. 
				;
				;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			MIT License
				;
				;			Copyright (c) 2024 John G. Lynch
				;
				;				Permission is hereby granted, free of charge, to any person obtaining a copy
				;				of this software and associated documentation files (the "Software"), to deal
				;				in the Software without restriction, including without limitation the rights
				;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
				;				copies of the Software, and to permit persons to whom the Software is
				;				furnished to do so, subject to the following conditions:
				;
				;				The above copyright notice and this permission notice shall be included in all
				;				copies or substantial portions of the Software.
				;
				;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
				;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
				;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
				;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
				;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
				;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
				;				SOFTWARE.
				;
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------

								INCLUDE			ui512aMacros.inc
			      C .NOLIST
			      C .LIST
			      C IFNDEF			ui512aMacros_INC
 = 1			      C ui512aMacros_INC EQU		<1>
			      C 
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512a.asm)
			      C 
			      C ;	// void zero_u ( u64* destarr ); 
			      C ;	// fill supplied 512bit (8 QWORDS) with zero
			      C EXTERNDEF		zero_u:PROC
			      C 
			      C ;	// void copy_u ( u64* destarr, u64* srcarr );
			      C ;	// copy supplied 512bit (8 QWORDS) source to supplied destination
			      C EXTERNDEF		copy_u:PROC
			      C 
			      C ;	// void set_uT64 ( u64* destarr, u64 value );
			      C ;	// set supplied destination 512 bit to supplied u64 value
			      C EXTERNDEF		set_uT64:PROC
			      C 
			      C ;	// s16 compare_u ( u64* lh_op, u64* rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_u:PROC
			      C 
			      C ;	// s16 compare_uT64 ( u64* lh_op, u64 rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand (value)
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_uT64:PROC
			      C 
			      C ;	// s16 add_u ( u64* sum, u64* addend1, u64* addend2 );
			      C ;	// add supplied 512bit (8 QWORDS) sources, place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_u:PROC
			      C 
			      C ;	// s16 add_uT64 ( u64* sum, u64* addend1, u64 addend2 );
			      C ;	// add 64bit QWORD (value) to supplied 512bit (8 QWORDS), place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_uT64:PROC
			      C 
			      C ;	// s16 sub_u ( u64* difference, u64* left operand, u64* right operand );
			      C ;	// subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_u:PROC
			      C 
			      C ;	// s16 sub_uT64( u64* difference, u64* left operand, u64 right operand );
			      C ;	// subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_uT64:PROC
			      C 
			      C ;			Configuration choices
 = 00000001		      C __UseZ			EQU				1									; Use AVX4 processor features (512 bit registers and instructions)
 = 00000000		      C __UseY			EQU				0									; Use AVX2 processor features (256 bit registers and instructions)
 = 00000000		      C __UseX			EQU				0									; Use SIMD/SSE processor features (128 bit registers and instructions)
 = 00000000		      C __UseQ			EQU				0									; Do not use extensions, use standard x64 bit registers and instructions
			      C ;
 = 00000000		      C __CheckAlign	EQU				0									; User is expected to pass arguments aligned on 64 byte boundaries, 
			      C 																	; This setting enforces that with a check. It should not be necessary, but included to help debugging
			      C 
			      C ;           Some coding shortcuts
 = ZMMWORD PTR		      C ZM_PTR			EQU				ZMMWORD PTR
 = YMMWORD PTR		      C YM_PTR			EQU				YMMWORD PTR
 = XMMWORD PTR		      C XM_PTR			EQU				XMMWORD PTR
 = QWORD PTR		      C Q_PTR			EQU				QWORD PTR
 = DWORD PTR		      C D_PTR			EQU				DWORD PTR
 = WORD PTR		      C W_PTR			EQU				WORD PTR
 = BYTE PTR		      C B_PTR			EQU				BYTE PTR
 = DWORD BCST		      C m32BCST			EQU				DWORD BCST
 = QWORD BCST		      C m64BCST			EQU				QWORD BCST
			      C 
			      C ;			mask codes (for compares using instructions like VPCMPUQ)
 = 00000000		      C CPEQ			EQU				0
 = 00000001		      C CPLT			EQU				1
 = 00000002		      C CPLE			EQU				2
 = 00000003		      C CPFALSE			EQU				3
 = 00000004		      C CPNE			EQU				4
 = 00000005		      C CPGE			EQU				5
 = 00000006		      C CPGT			EQU				6
 = 00000007		      C CPTRUE			EQU				7
			      C 
			      C ;			Mask values (for k reg) used to select particulare QWORDS from X, Y, or Z simd regs
 = 00000001		      C MaskBit0		EQU				B_PTR [ 00000001b ]
 = 00000002		      C MaskBit1		EQU				B_PTR [ 00000010b ]
 = 00000004		      C MaskBit2		EQU				B_PTR [ 00000100b ]
 = 00000008		      C MaskBit3		EQU				B_PTR [ 00001000b ]
 = 00000010		      C MaskBit4		EQU				B_PTR [ 00010000b ]
 = 00000020		      C MaskBit5		EQU				B_PTR [ 00100000b ]
 = 00000040		      C MaskBit6		EQU				B_PTR [ 01000000b ]
 = 00000080		      C MaskBit7		EQU				B_PTR [ 10000000b ]
			      C 
			      C ;			Another way to get masks
			      C kMask			RECORD			b8:1, b7:1, b6:1, b5:1, b4:1, b3:1, b2:1, b1:1, b0:1
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ; return (if any) is in EAX
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C 
			      C ;===========================================================================================
			      C ;          Local macros
			      C ;===========================================================================================
			      C 
			      C ;
			      C ;			Test passed variable addresses for 64 byte alignment
			      C ;			Note: Better performance if this is off, but for debugging, maybe have it on
			      C ;
			      C CheckAlign		MACRO			Raddr
			      C 				LOCAL			ok
			      C 	IF	__CheckAlign
			      C 				TEST			Raddr, 63							; Is specified param aligned 64?
			      C 				JZ				ok									; Yes, passes test, continue
			      C 				INT				0									; No, fails, break (can substitute other exception handling)
			      C ok:
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C MemConstants	MACRO
			      C ;		Return codes commonly used.			
			      C ret0			DD				0								
			      C ret1			DD				1
			      C ret_1			DD				-1
			      C ;		Masks commonly used
			      C mskAll8			DB				255
			      C mskB0			DB				1
			      C mskB1			DB				2
			      C mskB2			DB				4
			      C mskB3			DB				8
			      C mskB4			DB				16
			      C mskB5			DB				32
			      C mskB6			DB				64
			      C mskB7			DB				128
			      C mskHex100		DD				0100h
			      C 				ENDM
			      C 
			      C ;
			      C ;			Zero a 512 bit destination, conditional assembly based on configuration parameters
			      C ;
			      C Zero512			MACRO			dest
			      C 				CheckAlign		dest
			      C 	IF	__UseZ
			      C 				VPXORQ			ZMM31, ZMM31, ZMM31
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VPXORQ			YMM4, YMM4, YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM4
			      C 	ELSEIF	__UseX
			      C 				PXOR			XMM4, XMM4
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM4			
			      C 	ELSE
			      C 				XOR				RAX, RAX
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C 
			      C ;
			      C ;			Copy a 512 bit source to destination, conditional assembly based on configuration parameters
			      C ;
			      C Copy512			MACRO			dest, src
			      C 				CheckAlign		dest
			      C 				CheckAlign		src
			      C 	IF	__UseZ
			      C 				VMOVDQA64		ZMM31, ZM_PTR [ src ]
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VMOVDQA64		YMM4, YM_PTR [ src + 0 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			      C 				VMOVDQA64		YMM5, YM_PTR [ src + 4 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM5
			      C 	ELSEIF	__UseX
			      C 				MOVDQA			XMM4, XM_PTR [ src + 0 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 2 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM3
			      C 				MOVDQA			XMM4, XM_PTR [ src + 4 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 6 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM3
			      C 	ELSE
			      C 				MOV				RAX, [ src + 0 * 8 ]
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				RAX, [ src + 1 * 8 ]
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				RAX, [ src + 2 * 8 ]
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				RAX, [ src + 3 * 8 ]
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				RAX, [ src + 4 * 8 ]
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				RAX, [ src + 5 * 8 ]
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				RAX, [ src + 6 * 8 ]
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				RAX, [ src + 7 * 8 ]
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C ;
			      C ;			Get a GP reg QWORD from within a Z register as specified by mask
			      C ;			Note: RAX, ZMM0 and k1 are used and not restored
			      C ;			Example usage: GetZatIdx R11, ZMM1, MaskBit2 or SetZatIdx ZMM1, R12, [ R9 ]  (where R9 is a bit mask, not an integer index)
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C GetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX,  mask
			      C 				KMOVB			k1, RAX
			      C 				VPCOMPRESSQ		ZMM0 {k1}{z}, src
			      C 				VMOVQ			dest, XMM0
			      C 				ENDM
			      C 
			      C ;
			      C ;			Set a GP Reg QWORD within a Z register as specified by mask
			      C ;			Note: RAX and k1 are used and not restored
			      C ;			Example usage: SetZatIdx ZMM1, R8, MaskBit2
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C SetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX, mask
			      C 				KMOVB			k1, RAX
			      C 				VPBROADCASTQ 	dest {k1}, src
			      C 				ENDM
			      C ENDIF
			      C 
								OPTION			casemap:none
 00000000			.CODE
								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none

								MemConstants
 00000000 00000000	     1	ret0			DD				0								
 00000004 00000001	     1	ret1			DD				1
 00000008 FFFFFFFF	     1	ret_1			DD				-1
 0000000C FF		     1	mskAll8			DB				255
 0000000D 01		     1	mskB0			DB				1
 0000000E 02		     1	mskB1			DB				2
 0000000F 04		     1	mskB2			DB				4
 00000010 08		     1	mskB3			DB				8
 00000011 10		     1	mskB4			DB				16
 00000012 20		     1	mskB5			DB				32
 00000013 40		     1	mskB6			DB				64
 00000014 80		     1	mskB7			DB				128
 00000015 00000100	     1	mskHex100		DD				0100h

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			zero_u		-	fill supplied 512bit (8 QWORDS) with zero
				;			Prototype:		extern "C" void zero_u ( u64* destarr );
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			returns		-	nothing
				;
 00000019			zero_u			PROC			PUBLIC
								Zero512			RCX									; Zero 512 bit space addressed in RCX (the parameter)
 00000019  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 0000001F  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 00000025  C3							RET		
 00000026			zero_u			ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			copy_u		-	copy supplied 512bit (8 QWORDS) source to supplied destination
				;			Prototype:		extern "C" void copy_u( u64* destarr, u64* srcarr )
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			srcarr		-	Address of source 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			returns		-	nothing
				;
 00000026			copy_u			PROC			PUBLIC
								Copy512			RCX, RDX							; Copy 512 bit space from scr array (address in RDX) to dest (RCX)
 00000026  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 0000002C  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 00000032  C3							RET	
 00000033			copy_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			setuT64		-	set supplied destination 512 bit to supplied u64 value
				;			Prototype:		extern "C" void set_uT64( u64* destarr, u64 value )
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			src			-	u64 value in RDX
				;			returns		-	nothing
				;
 00000033			set_uT64		PROC			PUBLIC
								Zero512			RCX	
 00000033  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000039  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 0000003F  48/ 89 51 38						MOV				Q_PTR [ RCX + 7 * 8 ], RDX
 00000043  C3							RET	
 00000044			set_uT64		ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			compare_u	-	unsigned compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
				;			Prototype:		extern "C" s32 compare_u( u64* lh_op, u64* rh_op )
				;			lh_op		-	Address of LH 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			rh_op		-	Address of RH 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			returns		-	(0) for equal, -1 for less than, 1 for greater than
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 00000044			compare_u		PROC			PUBLIC

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ
 00000044  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [ RCX ]				; Load parameters
	   31
 0000004A  62 61 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 00000050  62 93 8D 40/ 1E					VPCMPUQ			K1, ZMM30, ZMM31, CPLT				; in-lane compare 8 words for 'less than'
	   CF 01
 00000057  C5 78/ 93 C1						KMOVW			R8D, K1
 0000005B  41/ 81 C8						OR				R8D, MASK kMask.b8					; OR in a high bit to make an equal compare not zero	
	   00000100
 00000062  41/ D1 E0						SHL				R8D, 1								; shift to get bits 2 through 8
 00000065  45/ 0F BC C0						BSF				R8D, R8D							; get bit number of right-most (most significant) 1 thru 8
 00000069  62 93 8D 40/ 1E					VPCMPUQ			K2, ZMM30, ZMM31, CPGT				; do the same for 'greater than'
	   D7 06
 00000070  C5 F8/ 93 C2						KMOVW			EAX, K2
 00000074  0D 00000100						OR				EAX, MASK kMask.b8					; OR in a high bit to make an equal compare not zero				
 00000079  D1 E0						SHL				EAX, 1
 0000007B  0F BC C0						BSF				EAX, EAX
 0000007E  44/ 3B C0						CMP				R8D, EAX							; compare: which is most significant? LT or GT? (or zero - equal)
 00000081  8B 05 00000000 R					MOV				EAX, ret0
 00000087  0F 4F 05						CMOVG			EAX, ret1
	   00000004 R
 0000008E  0F 4C 05						CMOVL			EAX, ret_1
	   00000008 R
 00000095  C3							RET

					ELSEIF	__UseY
					ENDIF
 00000096			compare_u		ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			compare_uT64-	unsigned compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand
				;			Prototype:		extern "C" s32 compare_uT64( u64* lh_op, u64 rh_op )
				;			lh_op		-	Address of LH 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			rh_op		-	The RH 64-bit value in RDX
				;			returns		-	(0) for equal, -1 for less than, 1 for greater than
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 00000096			compare_uT64	PROC			PUBLIC
								
								CheckAlign		RCX

					IF		__UseZ
 00000096  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [ RCX ]				; Load lh-op parameter
	   31
 0000009C  48/ 8D 04 25						LEA				RAX, MaskBit7
	   00000080
 000000A4  C5 F9/ 92 C8						KMOVB			K1, RAX
 000000A8  62 62 FD C9/ 7C					VPBROADCASTQ 	ZMM31 {k1}{z}, RDX					; load rh_op parameter (both now in Z regs)
	   FA
 000000AE  62 93 8D 40/ 1E					VPCMPUQ			K1, ZMM30, ZMM31, CPLT				; in-lane compare for LT
	   CF 01
 000000B5  C5 78/ 93 C1						KMOVW			R8D, K1
 000000B9  41/ 81 C8						OR				R8D, MASK kMask.b8					; OR in a high bit to make an equal compare not zero	
	   00000100
 000000C0  41/ D1 E0						SHL				R8D, 1								; shift to get bits 2 through 8
 000000C3  45/ 0F BC C0						BSF				R8D, R8D							; get bit number of right-most (most significant) 1 thru 8
 000000C7  62 93 8D 40/ 1E					VPCMPUQ			K2, ZMM30, ZMM31, CPGT				; do the same for 'greater than'
	   D7 06
 000000CE  C5 F8/ 93 C2						KMOVW			EAX, K2
 000000D2  0D 00000100						OR				EAX, MASK kMask.b8					; OR in a high bit to make an equal compare not zero	
 000000D7  D1 E0						SHL				EAX, 1
 000000D9  0F BC C0						BSF				EAX, EAX
 000000DC  44/ 3B C0						CMP				R8D, EAX							; compare: which is most significant? LT or GT? (or zero - equal)
 000000DF  8B 05 00000000 R					MOV				EAX, ret0
 000000E5  0F 4F 05						CMOVG			EAX, ret1
	   00000004 R
 000000EC  0F 4C 05						CMOVL			EAX, ret_1
	   00000008 R
 000000F3  C3							RET

					ELSE
					ENDIF
 000000F4			compare_uT64 ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			add_u		-	unsigned add supplied 512bit (8 QWORDS) sources to supplied destination
				;			Prototype:		extern "C" s32 add_u( u64* sum, u64* addend1, u64* addend2 )
				;			sum			-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			addend1		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			addend2		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in R8
				;			returns		-	zero for no carry, 1 for carry (overflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 000000F4			add_u			PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX
								CheckAlign		R8	

					IF	__UseZ
				;
				;	__UseZ approach
				;		Load operands into ZMM regs. Do in-lane qword adds (simultaneously)
				;		Compare result to addend to see if any carries (in-lane simultaneous compare)
				;		If there are carries: determine which lanes, add 1 to next most significant word(s) 
				;		Special case: if highest order word carried, set overflow
				;		Add of carries may cause additional carries, so repeat until no carries
				;
				;		Best case: no carries - 12 instructions.
				;		Worst case: 0xFFF...FFF + 1: an eight word cascading carry all the way to overflow: loops seven times - 82 instruction
				;
				; Load operands				
 000000F4  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; ZMM30 = addend1 (8 QWORDs)
	   32
 000000FA  62 41 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [R8]					; ZMM31 = addend2 (8 QWORDs)
	   38

				; Set up loop variables: R9 to be broadcast for adding carries (a one), RAX for tracking all the carries
 00000100  4D/ 33 C9						XOR				R9, R9
 00000103  49/ FF C1						INC				R9
 00000106  48/ 33 C0						XOR				RAX, RAX							; Carry flag and return code, persistant through iterations

				; Initial addition
 00000109  62 01 8D 40/ D4					VPADDQ		    ZMM29, ZMM30, ZMM31					; ZMM29 = addend1 + addend2 (lane-by-lane)
	   EF

				; Compute carries from (first) in-lane addition
 0000010F  62 93 95 40/ 1E					VPCMPUQ		    K1, ZMM29, ZMM30, CPLT				; k1[i] = 1 if sum[i] < addend1[i] (carry out of lane i)
	   CE 01

				; Examine computed carries: Most sig bit? indicates overall carry overflow; shift to align, if then none? we are done; 
 00000116			@@checkcarry:
 00000116  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8 
 0000011A  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore carries already added in. Do THESE carries, AND NOT carries already done
 0000011F  49/ 0B C0						OR				RAX, R8								; Keep these carries, along with the prior carries
 00000122  49/ D1 E8						SHR				R8, 1								; Shift right: carry-in for each lane (from lane i+1 to i)	
 00000125  74 1A						JZ				@@saveexit							; if, after alignment shift, there are no carries: save and exit

				; anything else, and for as long as these additions cause carries, add one to each carried into SIMD lane
 00000127  C4 C1 79/ 92 C8					KMOVB			K1, R8
 0000012C  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 } { z }, R9				; ZMM28 = carry-ins broadcast to selected lanes, zero non-selected lanes
	   E1
 00000132  62 01 95 41/ D4					VPADDQ			ZMM29 { k1 }, ZMM29, ZMM28			; Add carry-ins to selected lanes
	   EC
 00000138  62 93 95 41/ 1E					VPCMPUQ			K1 { k1 }, ZMM29, ZMM28, CPLT		; k2[i] = 1 if new sum[i] < carry-in[i] (new carries) Compute any new carries
	   CC 01
 0000013F  EB D5						JMP				@@checkcarry

				; store final sum
 00000141			@@saveexit:
 00000141  48/ 83 E0 01						AND				RAX, 1								; Bit 1 signifies a carry out of most significant word (an overflow) -> return code
 00000145  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29					; Store final sum
	   29
 0000014B  C3							RET													; EAX carries return code (from carry computation above)

					ELSE
					ENDIF
 0000014C			add_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			add_uT64	-	add supplied 64bit QWORD (value) to 512bit (8 QWORDS), place in supplied destination
				;			Prototype:		extern "C" s32 add_uT64( u64* sum, u64* addend1, u64 addend2 )
				;			sum			-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			addend1		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			addend2		-	The 64-bit value in R8
				;			returns		-	zero for no carry, 1 for carry (overflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 0000014C			add_uT64		PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ
				; Load operands				
 0000014C  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; ZMM30 = addend1 (8 QWORDs)
	   32
 00000152  C5 F9/ 90 0D						KMOVB			K1, mskB7							; mask for least significant word
	   00000014 R
 0000015A  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM31 { k1 } { z }, R8				; ZMM31 now 512 bit version of passed addend2
	   F8

				; Set up loop variables: R9 to be broadcast for adding carries, RAX for tracking all the carries
 00000160  4D/ 33 C9						XOR				R9, R9
 00000163  49/ FF C1						INC				R9
 00000166  48/ 33 C0						XOR				RAX, RAX							; Carry flag and return code, persistant through iterations

				; Initial addition
 00000169  62 01 8D 40/ D4					VPADDQ		    ZMM29, ZMM30, ZMM31					; ZMM29 = addend1 + addend2 (lane-wise)
	   EF

				; Compute carries from (first) in-lane addition
 0000016F  62 93 95 40/ 1E					VPCMPUQ		    K1, ZMM29, ZMM30, CPLT				; k1[i] = 1 if sum[i] < addend1[i] (carry out of lane i)
	   CE 01

				; Examine computed carries: MSB? indicates overall carry overflow; shift to align, if then none? we are done; 
 00000176			@@checkcarry:
 00000176  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8
 0000017A  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore carries already added in. Do these carries, AND NOT carries already done
 0000017F  49/ 0B C0						OR				RAX, R8								; Keep these carries, along with the prior carries
 00000182  49/ D1 E8						SHR				R8, 1								; Shift right: carry-in for each lane (from lane i+1 to i)	
 00000185  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no carries, save and exit

				; anything else, and for as long as these additions cause carries, add one to each carried into SIMD lane
 00000187  C4 C1 79/ 92 C8					KMOVB			K1, R8
 0000018C  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 } { z }, R9				; ZMM28 = carry-ins broadcast to selected lanes, zero non-selected lanes
	   E1
 00000192  62 01 95 41/ D4					VPADDQ			ZMM29 { k1 }, ZMM29, ZMM28			; Add carry-ins to selected lanes
	   EC
 00000198  62 93 95 41/ 1E					VPCMPUQ			K1 { k1 }, ZMM29, ZMM28, CPLT		; k2[i] = 1 if new sum[i] < carry-in[i] (new carries) Compute any new carries
	   CC 01
 0000019F  EB D5						JMP				@@checkcarry

				; store final sum
 000001A1			@@saveexit:
 000001A1  48/ 83 E0 01						AND				RAX, 1								; Bit 1 signifies a carry out of most significant word (an overflow) -> return code
 000001A5  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29					; Store final sum
	   29
 000001AB  C3							RET													; EAX carries return code (from carry computation above)
					ELSE
					ENDIF

 000001AC			add_uT64		ENDP 
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			sub_u		-	subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
				;			Prototype:		extern "C" s32 sub_u( u64* difference, u64* left operand, u64* right operand )
				;			difference	-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			lh_op		-	Address of the LHOP 8 64-bit QWORDS (512 bits) in RDX
				;			rh_op		-	Address of the RHOP 8 64-bit QWORDS (512 bits) in R8
				;			returns		-	zero for no borrow, 1 for borrow (underflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 000001AC			sub_u			PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX
								CheckAlign		R8

					IF __UseZ

				; Load operands
 000001AC  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; Load lh_op
	   32
 000001B2  62 41 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [R8]					; Load rh_op
	   38

				; Initialize loop variables: R9 for the targeted in-lane subract of borrows; RAX for return code overall borrow flag
 000001B8  4D/ 33 C9						XOR				R9, R9
 000001BB  49/ FF C1						INC				R9
 000001BE  48/ 33 C0						XOR				RAX, RAX

				; Initial subraction
 000001C1  62 01 8D 40/ FB					VPSUBQ		    ZMM29, ZMM30, ZMM31					; Initial subtraction
	   EF

				; Compute initial borrows
 000001C7  62 93 8D 40/ 1E					VPCMPUQ		    K1, ZMM30, ZMM31, CPLT				; Initial borrows
	   CF 01

				; Examine computed borrows: 
 000001CE			@@checkborrow:
 000001CE  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R10 (and R8)
 000001D2  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore borrows already done. Do these borrows, AND NOT borrows already done
 000001D7  49/ 0B C0						OR				RAX, R8								; Keep these borrows, along with the prior borrows
 000001DA  49/ D1 E8						SHR				R8, 1								; Shift right: borrow-from for each lane (from lane i+1 to i)	
 000001DD  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no borrows, save and exit

				; anything else, and for as long as these subtractions cause borrows, subtract one from each borrowed from SIMD lane
 000001DF  C4 C1 79/ 92 C8					KMOVB			K1, R8
 000001E4  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 }  {z }, R9				; Apply borrow-ins only where needed
	   E1
 000001EA  62 01 95 41/ FB					VPSUBQ			ZMM29 { k1 }, ZMM29, ZMM28
	   EC
 000001F0  62 93 95 41/ 1E					VPCMPUQ			k1 { k1 }, ZMM29, ZMM28, CPGT		; compute new mask of borrows
	   CC 06
 000001F7  EB D5						JMP				@@checkborrow
 000001F9			@@saveexit:
 000001F9  48/ 83 E0 01						AND				RAX, 1
 000001FD  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29
	   29
 00000203  C3							RET

					ELSE
					ENDIF
 00000204			sub_u			ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			sub_uT64	-	subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
				;			Prototype:		extern "C" s32 sub_uT64( u64* difference, u64* left operand, u64 right operand )
				;			difference	-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			lh_op		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			rh_op		-	64-bitvalue in R8
				;			returns		-	zero for no borrow, 1 for borrow (underflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore
				;
 00000204			sub_uT64		PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ

				; Load operands
 00000204  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]			        ; Load lh_op
	   32
 0000020A  C5 F9/ 90 0D						KMOVB			K1, mskB7							; mask for least significant word
	   00000014 R
 00000212  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM31 { k1 } { z }, R8				; ZMM31 now 512 bit version of passed rh_op
	   F8

				; Initialize loop variables: R9 for the targeted in-lane subract of borrows; RAX for return code overall borrow flag
 00000218  4D/ 33 C9						XOR				R9, R9
 0000021B  49/ FF C1						INC				R9
 0000021E  48/ 33 C0						XOR				RAX, RAX

				; Initial subraction
 00000221  62 01 8D 40/ FB					VPSUBQ		    ZMM29, ZMM30, ZMM31					; Initial subtraction
	   EF

				; Compute initial borrows
 00000227  62 93 8D 40/ 1E					VPCMPUQ		    K1, ZMM30, ZMM31, CPLT				; Initial borrows
	   CF 01

				; Examine computed borrows: 
 0000022E			@@checkborrow:
 0000022E  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8
 00000232  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore borrows already done. Do these borrows, AND NOT borrows already done
 00000237  49/ 0B C0						OR				RAX, R8								; Keep these borrows, along with the prior borrows
 0000023A  49/ D1 E8						SHR				R8, 1								; Shift right: borrow-from for each lane (from lane i+1 to i)	
 0000023D  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no borrows, save and exit

				; anything else, and for as long as these subtractions cause borrows, subtract one from each borrowed from SIMD lane
 0000023F  C4 C1 79/ 92 C8					KMOVB			K1, R8
 00000244  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 }  {z }, R9				; Apply borrow-ins only where needed
	   E1
 0000024A  62 01 95 41/ FB					VPSUBQ			ZMM29 { k1 }, ZMM29, ZMM28
	   EC
 00000250  62 93 95 41/ 1E					VPCMPUQ			k1 { k1 }, ZMM29, ZMM28, CPGT		; compute new mask of borrows
	   CC 06
 00000257  EB D5						JMP				@@checkborrow
 00000259			@@saveexit:
 00000259  48/ 83 E0 01						AND				RAX, 1
 0000025D  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29
	   29
 00000263  C3							RET

					ELSE
					ENDIF

 00000264			sub_uT64		ENDP 

								END
Microsoft (R) Macro Assembler (x64) Version 14.43.34809.0   03/15/25 21:30:36
ui512a.asm						     Symbols 2 - 1




Macros:

                N a m e                 Type

CheckAlign . . . . . . . . . . .	Proc
Copy512  . . . . . . . . . . . .	Proc
GetZatMask . . . . . . . . . . .	Proc
MemConstants . . . . . . . . . .	Proc
SetZatMask . . . . . . . . . . .	Proc
Zero512  . . . . . . . . . . . .	Proc


Records:

                N a m e                  Width     # fields
                                         Shift     Width     Mask      Initial

kMask  . . . . . . . . . . . . .	 00000009      00000009
  b8 . . . . . . . . . . . . . .	 00000008      00000001	     0100     ?
  b7 . . . . . . . . . . . . . .	 00000007      00000001	     0080     ?
  b6 . . . . . . . . . . . . . .	 00000006      00000001	     0040     ?
  b5 . . . . . . . . . . . . . .	 00000005      00000001	     0020     ?
  b4 . . . . . . . . . . . . . .	 00000004      00000001	     0010     ?
  b3 . . . . . . . . . . . . . .	 00000003      00000001	     0008     ?
  b2 . . . . . . . . . . . . . .	 00000002      00000001	     0004     ?
  b1 . . . . . . . . . . . . . .	 00000001      00000001	     0002     ?
  b0 . . . . . . . . . . . . . .	 00000000      00000001	     0001     ?


Procedures, parameters, and locals:

                N a m e                 Type     Value    Attr

add_uT64 . . . . . . . . . . . .	P 	 0000014C _TEXT	Length= 00000060 Public
  @@checkcarry . . . . . . . . .	L 	 00000176 _TEXT	
  @@saveexit . . . . . . . . . .	L 	 000001A1 _TEXT	
add_u  . . . . . . . . . . . . .	P 	 000000F4 _TEXT	Length= 00000058 Public
  @@checkcarry . . . . . . . . .	L 	 00000116 _TEXT	
  @@saveexit . . . . . . . . . .	L 	 00000141 _TEXT	
compare_uT64 . . . . . . . . . .	P 	 00000096 _TEXT	Length= 0000005E Public
compare_u  . . . . . . . . . . .	P 	 00000044 _TEXT	Length= 00000052 Public
copy_u . . . . . . . . . . . . .	P 	 00000026 _TEXT	Length= 0000000D Public
set_uT64 . . . . . . . . . . . .	P 	 00000033 _TEXT	Length= 00000011 Public
sub_uT64 . . . . . . . . . . . .	P 	 00000204 _TEXT	Length= 00000060 Public
  @@checkborrow  . . . . . . . .	L 	 0000022E _TEXT	
  @@saveexit . . . . . . . . . .	L 	 00000259 _TEXT	
sub_u  . . . . . . . . . . . . .	P 	 000001AC _TEXT	Length= 00000058 Public
  @@checkborrow  . . . . . . . .	L 	 000001CE _TEXT	
  @@saveexit . . . . . . . . . .	L 	 000001F9 _TEXT	
zero_u . . . . . . . . . . . . .	P 	 00000019 _TEXT	Length= 0000000D Public


Symbols:

                N a m e                 Type     Value    Attr

B_PTR  . . . . . . . . . . . . .	Text   	 BYTE PTR
CPEQ . . . . . . . . . . . . . .	Number	 00000000h   
CPFALSE  . . . . . . . . . . . .	Number	 00000003h   
CPGE . . . . . . . . . . . . . .	Number	 00000005h   
CPGT . . . . . . . . . . . . . .	Number	 00000006h   
CPLE . . . . . . . . . . . . . .	Number	 00000002h   
CPLT . . . . . . . . . . . . . .	Number	 00000001h   
CPNE . . . . . . . . . . . . . .	Number	 00000004h   
CPTRUE . . . . . . . . . . . . .	Number	 00000007h   
D_PTR  . . . . . . . . . . . . .	Text   	 DWORD PTR
MaskBit0 . . . . . . . . . . . .	Number	 00000001h   
MaskBit1 . . . . . . . . . . . .	Number	 00000002h   
MaskBit2 . . . . . . . . . . . .	Number	 00000004h   
MaskBit3 . . . . . . . . . . . .	Number	 00000008h   
MaskBit4 . . . . . . . . . . . .	Number	 00000010h   
MaskBit5 . . . . . . . . . . . .	Number	 00000020h   
MaskBit6 . . . . . . . . . . . .	Number	 00000040h   
MaskBit7 . . . . . . . . . . . .	Number	 00000080h   
Q_PTR  . . . . . . . . . . . . .	Text   	 QWORD PTR
W_PTR  . . . . . . . . . . . . .	Text   	 WORD PTR
XM_PTR . . . . . . . . . . . . .	Text   	 XMMWORD PTR
YM_PTR . . . . . . . . . . . . .	Text   	 YMMWORD PTR
ZM_PTR . . . . . . . . . . . . .	Text   	 ZMMWORD PTR
__CheckAlign . . . . . . . . . .	Number	 00000000h   
__UseQ . . . . . . . . . . . . .	Number	 00000000h   
__UseX . . . . . . . . . . . . .	Number	 00000000h   
__UseY . . . . . . . . . . . . .	Number	 00000000h   
__UseZ . . . . . . . . . . . . .	Number	 00000001h   
m32BCST  . . . . . . . . . . . .	Text   	 DWORD BCST
m64BCST  . . . . . . . . . . . .	Text   	 QWORD BCST
mskAll8  . . . . . . . . . . . .	Byte	 0000000C _TEXT	
mskB0  . . . . . . . . . . . . .	Byte	 0000000D _TEXT	
mskB1  . . . . . . . . . . . . .	Byte	 0000000E _TEXT	
mskB2  . . . . . . . . . . . . .	Byte	 0000000F _TEXT	
mskB3  . . . . . . . . . . . . .	Byte	 00000010 _TEXT	
mskB4  . . . . . . . . . . . . .	Byte	 00000011 _TEXT	
mskB5  . . . . . . . . . . . . .	Byte	 00000012 _TEXT	
mskB6  . . . . . . . . . . . . .	Byte	 00000013 _TEXT	
mskB7  . . . . . . . . . . . . .	Byte	 00000014 _TEXT	
mskHex100  . . . . . . . . . . .	DWord	 00000015 _TEXT	
ret0 . . . . . . . . . . . . . .	DWord	 00000000 _TEXT	
ret1 . . . . . . . . . . . . . .	DWord	 00000004 _TEXT	
ret_1  . . . . . . . . . . . . .	DWord	 00000008 _TEXT	
ui512aMacros_INC . . . . . . . .	Text   	 1

	   0 Warnings
	   0 Errors

Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   02/27/25 21:48:03
ui512a.asm						     Page 1 - 1


				;
				;			ui512a
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			File:			ui512a.asm
				;			Author:			John G. Lynch
				;			Legal:			Copyright @2024, per MIT License below
				;			Date:			May 13, 2024
				;
				;			Notes:
				;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
				;
				;				ui512a provides basic operations: zero, copy, compare, add, subtract.
				;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
				;               ui512md provides multiply and divide.
				;
				;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
				;				(currently using VS Community 2022 17.9.6)
				;
				;				It provides external signatures that allow linkage to C and C++ programs,
				;				where a shell/wrapper could encapsulate the methods as part of an object.
				;
				;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
				;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
				;
				;				If processor extensions are used, the caller must align the variables declared and passed
				;				on the appropriate byte boundary (e.g. alignas 64 for 512)
				;
				;				This module is very light-weight (less than 1K bytes) and relatively fast,
				;				but is not intended for all processor types or all environments. 
				;
				;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			MIT License
				;
				;			Copyright (c) 2024 John G. Lynch
				;
				;				Permission is hereby granted, free of charge, to any person obtaining a copy
				;				of this software and associated documentation files (the "Software"), to deal
				;				in the Software without restriction, including without limitation the rights
				;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
				;				copies of the Software, and to permit persons to whom the Software is
				;				furnished to do so, subject to the following conditions:
				;
				;				The above copyright notice and this permission notice shall be included in all
				;				copies or substantial portions of the Software.
				;
				;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
				;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
				;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
				;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
				;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
				;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
				;				SOFTWARE.
				;
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------

								INCLUDE			ui512aMacros.inc
			      C .nolist
			      C .list
			      C IFNDEF			ui512aMacros_INC
 = 1			      C ui512aMacros_INC EQU		<1>
			      C 
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512a.asm)
			      C 
			      C ;	// void zero_u ( u64* destarr ); 
			      C ;	// fill supplied 512bit (8 QWORDS) with zero
			      C EXTERNDEF		zero_u:PROC
			      C 
			      C ;	// void copy_u ( u64* destarr, u64* srcarr );
			      C ;	// copy supplied 512bit (8 QWORDS) source to supplied destination
			      C EXTERNDEF		copy_u:PROC
			      C 
			      C ;	// void set_uT64 ( u64* destarr, u64 value );
			      C ;	// set supplied destination 512 bit to supplied u64 value
			      C EXTERNDEF		set_uT64:PROC
			      C 
			      C ;	// s16 compare_u ( u64* lh_op, u64* rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_u:PROC
			      C 
			      C ;	// s16 compare_uT64 ( u64* lh_op, u64 rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand (value)
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_uT64:PROC
			      C 
			      C ;	// s16 add_u ( u64* sum, u64* addend1, u64* addend2 );
			      C ;	// add supplied 512bit (8 QWORDS) sources, place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_u:PROC
			      C 
			      C ;	// s16 add_uT64 ( u64* sum, u64* addend1, u64 addend2 );
			      C ;	// add 64bit QWORD (value) to supplied 512bit (8 QWORDS), place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_uT64:PROC
			      C 
			      C ;	// s16 sub_u ( u64* difference, u64* left operand, u64* right operand );
			      C ;	// subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_u:PROC
			      C 
			      C ;	// s16 sub_uT64( u64* difference, u64* left operand, u64 right operand );
			      C ;	// subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_uT64:PROC
			      C 
			      C ;			Configuration choices
 = 00000001		      C __UseZ			EQU				1									; Use AVX4 processor features (512 bit registers and instructions)
 = 00000000		      C __UseY			EQU				0									; Use AVX2 processor features (256 bit registers and instructions)
 = 00000000		      C __UseX			EQU				0									; Use SIMD/SSE processor features (128 bit registers and instructions)
 = 00000000		      C __UseQ			EQU				0									; Do not use extensions, use standard x64 bit registers and instructions
			      C ;
 = 00000000		      C __CheckAlign	EQU				0									; User is expected to pass arguments aligned on 64 byte boundaries, 
			      C 																	; This setting enforces that with a check. It should not be necessary, but included to help debugging
			      C 
			      C ;           Some coding shortcuts
 = ZMMWORD PTR		      C ZM_PTR			EQU				ZMMWORD PTR
 = YMMWORD PTR		      C YM_PTR			EQU				YMMWORD PTR
 = XMMWORD PTR		      C XM_PTR			EQU				XMMWORD PTR
 = QWORD PTR		      C Q_PTR			EQU				QWORD PTR
 = DWORD PTR		      C D_PTR			EQU				DWORD PTR
 = WORD PTR		      C W_PTR			EQU				WORD PTR
 = BYTE PTR		      C B_PTR			EQU				BYTE PTR
 = DWORD BCST		      C m32BCST			EQU				DWORD BCST
 = QWORD BCST		      C m64BCST			EQU				QWORD BCST
			      C 
			      C ;			mask codes (for compares using instructions like VPCMPUQ)
 = 00000000		      C CPEQ			EQU				0
 = 00000001		      C CPLT			EQU				1
 = 00000002		      C CPLE			EQU				2
 = 00000003		      C CPFALSE			EQU				3
 = 00000004		      C CPNE			EQU				4
 = 00000005		      C CPGE			EQU				5
 = 00000006		      C CPGT			EQU				6
 = 00000007		      C CPTRUE			EQU				7
			      C 
			      C ;			Mask values (for k reg) used to select particulare QWORDS from X, Y, or Z simd regs
 = 00000001		      C MaskBit0		EQU				B_PTR [ 00000001b ]
 = 00000002		      C MaskBit1		EQU				B_PTR [ 00000010b ]
 = 00000004		      C MaskBit2		EQU				B_PTR [ 00000100b ]
 = 00000008		      C MaskBit3		EQU				B_PTR [ 00001000b ]
 = 00000010		      C MaskBit4		EQU				B_PTR [ 00010000b ]
 = 00000020		      C MaskBit5		EQU				B_PTR [ 00100000b ]
 = 00000040		      C MaskBit6		EQU				B_PTR [ 01000000b ]
 = 00000080		      C MaskBit7		EQU				B_PTR [ 10000000b ]
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ; return (if any) is in EAX
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C 
			      C ;===========================================================================================
			      C ;          Local macros
			      C ;===========================================================================================
			      C 
			      C ;
			      C ;			Test passed variable addresses for 64 byte alignment
			      C ;			Note: Better performance if this is off, but for debugging, maybe have it on
			      C ;
			      C 
			      C CheckAlign		MACRO			Raddr
			      C 				LOCAL			ok
			      C 	IF	__CheckAlign
			      C 				TEST			Raddr, 63							; Is specified param aligned 64?
			      C 				JZ				ok									; Yes, passes test, continue
			      C 				INT				0									; No, fails, break (can substitute other exception handling)
			      C ok:
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C MemConstants	MACRO
			      C ;		Return codes commonly used.			
			      C ret0			DD				0								
			      C ret1			DD				1
			      C ret_1			DD				-1
			      C ;		Masks commonly used
			      C mskAll8			DB				255
			      C mskB0			DB				1
			      C mskB1			DB				2
			      C mskB2			DB				4
			      C mskB3			DB				8
			      C mskB4			DB				16
			      C mskB5			DB				32
			      C mskB6			DB				64
			      C mskB7			DB				128
			      C 				ENDM
			      C 
			      C ;
			      C ;			Zero a 512 bit destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Zero512			MACRO			dest
			      C 				CheckAlign		dest
			      C 	IF	__UseZ
			      C 				VPXORQ			ZMM31, ZMM31, ZMM31
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VPXORQ			YMM4, YMM4, YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM4
			      C 	ELSEIF	__UseX
			      C 				PXOR			XMM4, XMM4
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM4			
			      C 	ELSE
			      C 				XOR				RAX, RAX
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C 
			      C ;
			      C ;			Copy a 512 bit source to destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Copy512			MACRO			dest, src
			      C 				CheckAlign		dest
			      C 				CheckAlign		src
			      C 	IF	__UseZ
			      C 				VMOVDQA64		ZMM31, ZM_PTR [ src ]
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VMOVDQA64		YMM4, YM_PTR [ src + 0 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			      C 				VMOVDQA64		YMM5, YM_PTR [ src + 4 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM5
			      C 	ELSEIF	__UseX
			      C 				MOVDQA			XMM4, XM_PTR [ src + 0 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 2 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM3
			      C 				MOVDQA			XMM4, XM_PTR [ src + 4 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 6 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM3
			      C 	ELSE
			      C 				MOV				RAX, [ src + 0 * 8 ]
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				RAX, [ src + 1 * 8 ]
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				RAX, [ src + 2 * 8 ]
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				RAX, [ src + 3 * 8 ]
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				RAX, [ src + 4 * 8 ]
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				RAX, [ src + 5 * 8 ]
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				RAX, [ src + 6 * 8 ]
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				RAX, [ src + 7 * 8 ]
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C ;
			      C ;			Get a GP reg QWORD from within a Z register as specified by mask
			      C ;			Note: RAX, ZMM0 and k1 are used and not restored
			      C ;			Example usage: GetZatIdx R11, ZMM1, MaskBit2 or SetZatIdx ZMM1, R12, [ R9 ]  (where R9 is a bit mask, not an integer index)
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C GetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX,  mask
			      C 				KMOVB			k1, RAX
			      C 				VPCOMPRESSQ		ZMM0 {k1}{z}, src
			      C 				VMOVQ			dest, XMM0
			      C 				ENDM
			      C 
			      C ;
			      C ;			Set a GP Reg QWORD within a Z register as specified by mask
			      C ;			Note: RAX and k1 are used and not restored
			      C ;			Example usage: SetZatIdx ZMM1, R8, MaskBit2
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C SetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX, mask
			      C 				KMOVB			k1, RAX
			      C 				VPBROADCASTQ 	dest {k1}, src
			      C 				ENDM
			      C ENDIF
			      C 
								OPTION			casemap:none
 00000000			.CODE
								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none

								MemConstants
 00000000 00000000	     1	ret0			DD				0								
 00000004 00000001	     1	ret1			DD				1
 00000008 FFFFFFFF	     1	ret_1			DD				-1
 0000000C FF		     1	mskAll8			DB				255
 0000000D 01		     1	mskB0			DB				1
 0000000E 02		     1	mskB1			DB				2
 0000000F 04		     1	mskB2			DB				4
 00000010 08		     1	mskB3			DB				8
 00000011 10		     1	mskB4			DB				16
 00000012 20		     1	mskB5			DB				32
 00000013 40		     1	mskB6			DB				64
 00000014 80		     1	mskB7			DB				128

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			zero_u		-	fill supplied 512bit (8 QWORDS) with zero
				;			Prototype:		extern "C" void zero_u ( u64* destarr );
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			returns		-	nothing
				;

 00000015			zero_u			PROC			PUBLIC
								Zero512			RCX									; Zero 512 bit space addressed in RCX (the parameter)
 00000015  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 0000001B  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 00000021  C3							RET		
 00000022			zero_u			ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			copy_u		-	copy supplied 512bit (8 QWORDS) source to supplied destination
				;			Prototype:		extern "C" void copy_u( u64* destarr, u64* srcarr )
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			srcarr		-	Address of source 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			returns		-	nothing

 00000022			copy_u			PROC			PUBLIC
								Copy512			RCX, RDX							; Copy 512 bit space from scr array (address in RDX) to dest (RCX)
 00000022  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 00000028  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 0000002E  C3							RET	
 0000002F			copy_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			setuT64		-	set supplied destination 512 bit to supplied u64 value
				;			Prototype:		extern "C" void set_uT64( u64* destarr, u64 value )
				;			destarr		-	Address of destination 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			src			-	u64 value in RDX
				;			returns		-	nothing

 0000002F			set_uT64		PROC			PUBLIC
								Zero512			RCX	
 0000002F  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000035  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
 0000003B  48/ 89 51 38						MOV				Q_PTR [ RCX + 7 * 8 ], RDX
 0000003F  C3							RET	
 00000040			set_uT64		ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			compare_u	-	unsigned compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
				;			Prototype:		extern "C" s32 compare_u( u64* lh_op, u64* rh_op )
				;			lh_op		-	Address of LH 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			rh_op		-	Address of RH 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			returns		-	(0) for equal, -1 for less than, 1 for greater than
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 00000040			compare_u		PROC			PUBLIC

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ
 00000040  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [ RCX ]				; Load parameters
	   31
 00000046  62 61 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 0000004C  62 93 8D 40/ 1E					VPCMPUQ			K1, ZMM30, ZMM31, CPLT				; in-lane compare 8 words for 'less than'
	   CF 01
 00000053  C5 78/ 93 C1						KMOVW			R8D, K1
 00000057  41/ D1 E0						SHL				R8D, 1								; shift to get bits 2 through 8
 0000005A  45/ 0F BD C0						BSR				R8D, R8D							; get bit number of right-most (most significant) 1 thru 8
 0000005E  62 93 8D 40/ 1E					VPCMPUQ			K2, ZMM30, ZMM31, CPGT				; do the same for 'greater than'
	   D7 06
 00000065  C5 F8/ 93 C2						KMOVW			EAX, K2
 00000069  D1 E0						SHL				EAX, 1
 0000006B  0F BD C0						BSR				EAX, EAX
 0000006E  41/ 3B C0						CMP				EAX, R8D							; compare: which is most significant? LT or GT? (or zero - equal)
 00000071  8B 05 00000000 R					MOV				EAX, ret0
 00000077  0F 47 05						CMOVA			EAX, ret1
	   00000004 R
 0000007E  0F 42 05						CMOVB			EAX, ret_1
	   00000008 R
 00000085  C3							RET

					ELSEIF	__UseY
					ENDIF
 00000086			compare_u		ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			compare_uT64-	unsigned compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand
				;			Prototype:		extern "C" s32 compare_uT64( u64* lh_op, u64 rh_op )
				;			lh_op		-	Address of LH 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			rh_op		-	The RH 64-bit value in RDX
				;			returns		-	(0) for equal, -1 for less than, 1 for greater than
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 00000086			compare_uT64	PROC			PUBLIC
								
								CheckAlign		RCX

					IF		__UseZ
 00000086  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [ RCX ]				; Load lh-op parameter
	   31
 0000008C  48/ 8D 04 25						LEA				RAX, MaskBit7
	   00000080
 00000094  C5 F9/ 92 C8						KMOVB			K1, RAX
 00000098  62 62 FD C9/ 7C					VPBROADCASTQ 	ZMM31 {k1}{z}, RDX					; load rh_op parameter (both now in Z regs)
	   FA
 0000009E  62 93 8D 40/ 1E					VPCMPUQ			K1, ZMM30, ZMM31, CPLT				; in-lane compare for LT
	   CF 01
 000000A5  C5 78/ 93 C1						KMOVW			R8D, K1
 000000A9  41/ D1 E0						SHL				R8D, 1
 000000AC  45/ 0F BD C0						BSR				R8D, R8D							; get bit number of right-most (most significant) 1 thru 8
 000000B0  62 93 8D 40/ 1E					VPCMPUQ			K2, ZMM30, ZMM31, CPGT				; do the same for 'greater than'
	   D7 06
 000000B7  C5 F8/ 93 C2						KMOVW			EAX, K2
 000000BB  D1 E0						SHL				EAX, 1
 000000BD  0F BD C0						BSR				EAX, EAX
 000000C0  41/ 3B C0						CMP				EAX, R8D							; compare: which is most significant? LT or GT? (or zero - equal)
 000000C3  8B 05 00000000 R					MOV				EAX, ret0
 000000C9  0F 47 05						CMOVA			EAX, ret1
	   00000004 R
 000000D0  0F 42 05						CMOVB			EAX, ret_1
	   00000008 R
 000000D7  C3							RET

					ELSE
					ENDIF
 000000D8			compare_uT64 ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			add_u		-	unsigned add supplied 512bit (8 QWORDS) sources to supplied destination
				;			Prototype:		extern "C" s32 add_u( u64* sum, u64* addend1, u64* addend2 )
				;			sum			-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			addend1		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			addend2		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in R8
				;			returns		-	zero for no carry, 1 for carry (overflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 000000D8			add_u			PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX
								CheckAlign		R8	

					IF	__UseZ
				;
				;	__UseZ approach
				;		Load operands into ZMM regs. Do in-lane qword adds (simultaneously)
				;		Compare result to addend to see if any carries (in-lane simultaneous compare)
				;		If there are carries: determine which lanes, add 1 to next most significant word(s) 
				;		Special case: if highest order word carried, set overflow
				;		Add of carries may cause additional carries, so repeat until no carries
				;
				;		Best case: no carries - 12 instructions.
				;		Worst case: 0xFFF...FFF + 1: an eight word cascading carry all the way to overflow: loops seven times - 82 instruction
				;
				; Load operands				
 000000D8  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; ZMM30 = addend1 (8 QWORDs)
	   32
 000000DE  62 41 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [R8]					; ZMM31 = addend2 (8 QWORDs)
	   38

				; Set up loop variables: R9 to be broadcast for adding carries, RAX for tracking all the carries
 000000E4  4D/ 33 C9						XOR				R9, R9
 000000E7  49/ FF C1						INC				R9
 000000EA  48/ 33 C0						XOR				RAX, RAX							; Carry flag and return code, persistant through iterations

				; Initial addition
 000000ED  62 01 8D 40/ D4					VPADDQ		    ZMM29, ZMM30, ZMM31					; ZMM29 = addend1 + addend2 (lane-wise)
	   EF

				; Compute carries from (first) in-lane addition
 000000F3  62 93 95 40/ 1E					VPCMPUQ		    K1, ZMM29, ZMM30, CPLT				; k1[i] = 1 if sum[i] < addend1[i] (carry out of lane i)
	   CE 01

				; Examine computed carries: Most sig bit? indicates overall carry overflow; shift to align, if then none? we are done; 
 000000FA			@@checkcarry:
 000000FA  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8 
 000000FE  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore carries already added in. Do these carries, AND NOT carries already done
 00000103  49/ 0B C0						OR				RAX, R8								; Keep these carries, along with the prior carries
 00000106  49/ D1 E8						SHR				R8, 1								; Shift right: carry-in for each lane (from lane i+1 to i)	
 00000109  74 1A						JZ				@@saveexit							; if, after alignment shift, there are no carries: save and exit

				; anything else, and for as long as these additions cause carries, add one to each carried into SIMD lane			
										
 0000010B  C4 C1 79/ 92 C8					KMOVB			K1, R8
 00000110  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 } { z }, R9				; ZMM28 = carry-ins broadcast to selected lanes, zero non-selected lanes
	   E1
 00000116  62 01 95 41/ D4					VPADDQ			ZMM29 { k1 }, ZMM29, ZMM28			; Add carry-ins to selected lanes
	   EC
 0000011C  62 93 95 41/ 1E					VPCMPUQ			K1 { k1 }, ZMM29, ZMM28, CPLT		; k2[i] = 1 if new sum[i] < carry-in[i] (new carries) Compute any new carries
	   CC 01
 00000123  EB D5						JMP				@@checkcarry

				; store final sum

 00000125			@@saveexit:
 00000125  48/ 83 E0 01						AND				RAX, 1								; Bit 1 signifies a carry out of most significant word (an overflow) -> return code
 00000129  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29					; Store final sum
	   29
 0000012F  C3							RET													; EAX carries return code (from carry computation above)

					ELSE
					ENDIF
 00000130			add_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			add_uT64	-	add supplied 64bit QWORD (value) to 512bit (8 QWORDS), place in supplied destination
				;			Prototype:		extern "C" s32 add_uT64( u64* sum, u64* addend1, u64 addend2 )
				;			sum			-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			addend1		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			addend2		-	The 64-bit value in R8
				;			returns		-	zero for no carry, 1 for carry (overflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 00000130			add_uT64		PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ
				; Load operands				
 00000130  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; ZMM30 = addend1 (8 QWORDs)
	   32
 00000136  C5 F9/ 90 0D						KMOVB			K1, mskB7							; mask for least significant word
	   00000014 R
 0000013E  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM31 { k1 } { z }, R8				; ZMM31 now 512 bit version of passed addend2
	   F8

				; Set up loop variables: R9 to be broadcast for adding carries, RAX for tracking all the carries
 00000144  4D/ 33 C9						XOR				R9, R9
 00000147  49/ FF C1						INC				R9
 0000014A  48/ 33 C0						XOR				RAX, RAX							; Carry flag and return code, persistant through iterations

				; Initial addition
 0000014D  62 01 8D 40/ D4					VPADDQ		    ZMM29, ZMM30, ZMM31					; ZMM29 = addend1 + addend2 (lane-wise)
	   EF

				; Compute carries from (first) in-lane addition
 00000153  62 93 95 40/ 1E					VPCMPUQ		    K1, ZMM29, ZMM30, CPLT				; k1[i] = 1 if sum[i] < addend1[i] (carry out of lane i)
	   CE 01

				; Examine computed carries: MSB? indicates overall carry overflow; shift to align, if then none? we are done; 
 0000015A			@@checkcarry:
 0000015A  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8
 0000015E  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore carries already added in. Do these carries, AND NOT carries already done
 00000163  49/ 0B C0						OR				RAX, R8								; Keep these carries, along with the prior carries
 00000166  49/ D1 E8						SHR				R8, 1								; Shift right: carry-in for each lane (from lane i+1 to i)	
 00000169  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no carries, save and exit

				; anything else, and for as long as these additions cause carries, add one to each carried into SIMD lane			
										
 0000016B  C4 C1 79/ 92 C8					KMOVB			K1, R8
 00000170  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 } { z }, R9				; ZMM28 = carry-ins broadcast to selected lanes, zero non-selected lanes
	   E1
 00000176  62 01 95 41/ D4					VPADDQ			ZMM29 { k1 }, ZMM29, ZMM28			; Add carry-ins to selected lanes
	   EC
 0000017C  62 93 95 41/ 1E					VPCMPUQ			K1 { k1 }, ZMM29, ZMM28, CPLT		; k2[i] = 1 if new sum[i] < carry-in[i] (new carries) Compute any new carries
	   CC 01
 00000183  EB D5						JMP				@@checkcarry

				; store final sum

 00000185			@@saveexit:
 00000185  48/ 83 E0 01						AND				RAX, 1								; Bit 1 signifies a carry out of most significant word (an overflow) -> return code
 00000189  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29					; Store final sum
	   29
 0000018F  C3							RET													; EAX carries return code (from carry computation above)
					ELSE
					ENDIF

 00000190			add_uT64		ENDP 
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			sub_u		-	subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
				;			Prototype:		extern "C" s32 sub_u( u64* difference, u64* left operand, u64* right operand )
				;			difference	-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			lh_op		-	Address of the LHOP 8 64-bit QWORDS (512 bits) in RDX
				;			rh_op		-	Address of the RHOP 8 64-bit QWORDS (512 bits) in R8
				;			returns		-	zero for no borrow, 1 for borrow (underflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 00000190			sub_u			PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX
								CheckAlign		R8

					IF __UseZ

				; Load operands
 00000190  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]					; Load lh_op
	   32
 00000196  62 41 FD 48/ 6F					VMOVDQA64		ZMM31, ZM_PTR [R8]					; Load rh_op
	   38

				; Initialize loop variables: R9 for the targeted in-lane subract of borrows; RAX for return code overall borrow flag
 0000019C  4D/ 33 C9						XOR				R9, R9
 0000019F  49/ FF C1						INC				R9
 000001A2  48/ 33 C0						XOR				RAX, RAX

				; Initial subraction
 000001A5  62 01 8D 40/ FB					VPSUBQ		    ZMM29, ZMM30, ZMM31					; Initial subtraction
	   EF

				; Compute initial borrows
 000001AB  62 93 8D 40/ 1E					VPCMPUQ		    K1, ZMM30, ZMM31, CPLT				; Initial borrows
	   CF 01

				; Examine computed borrows: 
 000001B2			@@checkborrow:
 000001B2  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R10 (and R8)
 000001B6  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore borrows already done. Do these borrows, AND NOT borrows already done
 000001BB  49/ 0B C0						OR				RAX, R8								; Keep these borrows, along with the prior borrows
 000001BE  49/ D1 E8						SHR				R8, 1								; Shift right: borrow-from for each lane (from lane i+1 to i)	
 000001C1  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no borrows, save and exit

				; anything else, and for as long as these subtractions cause borrows, subtract one from each borrowed from SIMD lane
 000001C3  C4 C1 79/ 92 C8					KMOVB			K1, R8
 000001C8  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 }  {z }, R9				; Apply borrow-ins only where needed
	   E1
 000001CE  62 01 95 41/ FB					VPSUBQ			ZMM29 { k1 }, ZMM29, ZMM28
	   EC
 000001D4  62 93 95 41/ 1E					VPCMPUQ			k1 { k1 }, ZMM29, ZMM28, CPGT		; compute new mask of borrows
	   CC 06
 000001DB  EB D5						JMP				@@checkborrow
 000001DD			@@saveexit:
 000001DD  48/ 83 E0 01						AND				RAX, 1
 000001E1  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29
	   29
 000001E7  C3							RET

					ELSE
					ENDIF
 000001E8			sub_u			ENDP 

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			sub_uT64	-	subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
				;			Prototype:		extern "C" s32 sub_uT64( u64* difference, u64* left operand, u64 right operand )
				;			difference	-	Address of 64 byte alligned array of 8 64-bit words (QWORDS) 512 bits (in RCX)
				;			lh_op		-	Address of  the 64 byte aligned array of 8 64-bit QWORDS (512 bits) in RDX
				;			rh_op		-	64-bitvalue in R8
				;			returns		-	zero for no borrow, 1 for borrow (underflow)
				;			Note: unrolled code instead of loop: faster, and no regs to save / setup / restore

 000001E8			sub_uT64		PROC			PUBLIC 

								CheckAlign		RCX
								CheckAlign		RDX

					IF __UseZ

				; Load operands
 000001E8  62 61 FD 48/ 6F					VMOVDQA64		ZMM30, ZM_PTR [RDX]			        ; Load lh_op
	   32
 000001EE  C5 F9/ 90 0D						KMOVB			K1, mskB7							; mask for least significant word
	   00000014 R
 000001F6  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM31 { k1 } { z }, R8				; ZMM31 now 512 bit version of passed rh_op
	   F8

				; Initialize loop variables: R9 for the targeted in-lane subract of borrows; RAX for return code overall borrow flag
 000001FC  4D/ 33 C9						XOR				R9, R9
 000001FF  49/ FF C1						INC				R9
 00000202  48/ 33 C0						XOR				RAX, RAX

				; Initial subraction
 00000205  62 01 8D 40/ FB					VPSUBQ		    ZMM29, ZMM30, ZMM31					; Initial subtraction
	   EF

				; Compute initial borrows
 0000020B  62 93 8D 40/ 1E					VPCMPUQ		    K1, ZMM30, ZMM31, CPLT				; Initial borrows
	   CF 01

				; Examine computed borrows: 
 00000212			@@checkborrow:
 00000212  C5 79/ 93 C1						KMOVB			R8, K1								; Mask bits results (from compare above) in k1 to R8
 00000216  C4 42 F8/ F2 C0					ANDN			R8, RAX, R8							; Ignore borrows already done. Do these borrows, AND NOT borrows already done
 0000021B  49/ 0B C0						OR				RAX, R8								; Keep these borrows, along with the prior borrows
 0000021E  49/ D1 E8						SHR				R8, 1								; Shift right: borrow-from for each lane (from lane i+1 to i)	
 00000221  74 1A						JZ				@@saveexit							; If, after alignment shift, there are no borrows, save and exit

				; anything else, and for as long as these subtractions cause borrows, subtract one from each borrowed from SIMD lane
 00000223  C4 C1 79/ 92 C8					KMOVB			K1, R8
 00000228  62 42 FD C9/ 7C					VPBROADCASTQ	ZMM28 { k1 }  {z }, R9				; Apply borrow-ins only where needed
	   E1
 0000022E  62 01 95 41/ FB					VPSUBQ			ZMM29 { k1 }, ZMM29, ZMM28
	   EC
 00000234  62 93 95 41/ 1E					VPCMPUQ			k1 { k1 }, ZMM29, ZMM28, CPGT		; compute new mask of borrows
	   CC 06
 0000023B  EB D5						JMP				@@checkborrow
 0000023D			@@saveexit:
 0000023D  48/ 83 E0 01						AND				RAX, 1
 00000241  62 61 FD 48/ 7F					VMOVDQA64		ZM_PTR [RCX], ZMM29
	   29
 00000247  C3							RET

					ELSE
					ENDIF

 00000248			sub_uT64		ENDP 

								END
Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   02/27/25 21:48:03
ui512a.asm						     Symbols 2 - 1




Macros:

                N a m e                 Type

CheckAlign . . . . . . . . . . .	Proc
Copy512  . . . . . . . . . . . .	Proc
GetZatMask . . . . . . . . . . .	Proc
MemConstants . . . . . . . . . .	Proc
SetZatMask . . . . . . . . . . .	Proc
Zero512  . . . . . . . . . . . .	Proc


Procedures, parameters, and locals:

                N a m e                 Type     Value    Attr

add_uT64 . . . . . . . . . . . .	P 	 00000130 _TEXT	Length= 00000060 Public
  @@checkcarry . . . . . . . . .	L 	 0000015A _TEXT	
  @@saveexit . . . . . . . . . .	L 	 00000185 _TEXT	
add_u  . . . . . . . . . . . . .	P 	 000000D8 _TEXT	Length= 00000058 Public
  @@checkcarry . . . . . . . . .	L 	 000000FA _TEXT	
  @@saveexit . . . . . . . . . .	L 	 00000125 _TEXT	
compare_uT64 . . . . . . . . . .	P 	 00000086 _TEXT	Length= 00000052 Public
compare_u  . . . . . . . . . . .	P 	 00000040 _TEXT	Length= 00000046 Public
copy_u . . . . . . . . . . . . .	P 	 00000022 _TEXT	Length= 0000000D Public
set_uT64 . . . . . . . . . . . .	P 	 0000002F _TEXT	Length= 00000011 Public
sub_uT64 . . . . . . . . . . . .	P 	 000001E8 _TEXT	Length= 00000060 Public
  @@checkborrow  . . . . . . . .	L 	 00000212 _TEXT	
  @@saveexit . . . . . . . . . .	L 	 0000023D _TEXT	
sub_u  . . . . . . . . . . . . .	P 	 00000190 _TEXT	Length= 00000058 Public
  @@checkborrow  . . . . . . . .	L 	 000001B2 _TEXT	
  @@saveexit . . . . . . . . . .	L 	 000001DD _TEXT	
zero_u . . . . . . . . . . . . .	P 	 00000015 _TEXT	Length= 0000000D Public


Symbols:

                N a m e                 Type     Value    Attr

B_PTR  . . . . . . . . . . . . .	Text   	 BYTE PTR
CPEQ . . . . . . . . . . . . . .	Number	 00000000h   
CPFALSE  . . . . . . . . . . . .	Number	 00000003h   
CPGE . . . . . . . . . . . . . .	Number	 00000005h   
CPGT . . . . . . . . . . . . . .	Number	 00000006h   
CPLE . . . . . . . . . . . . . .	Number	 00000002h   
CPLT . . . . . . . . . . . . . .	Number	 00000001h   
CPNE . . . . . . . . . . . . . .	Number	 00000004h   
CPTRUE . . . . . . . . . . . . .	Number	 00000007h   
D_PTR  . . . . . . . . . . . . .	Text   	 DWORD PTR
MaskBit0 . . . . . . . . . . . .	Number	 00000001h   
MaskBit1 . . . . . . . . . . . .	Number	 00000002h   
MaskBit2 . . . . . . . . . . . .	Number	 00000004h   
MaskBit3 . . . . . . . . . . . .	Number	 00000008h   
MaskBit4 . . . . . . . . . . . .	Number	 00000010h   
MaskBit5 . . . . . . . . . . . .	Number	 00000020h   
MaskBit6 . . . . . . . . . . . .	Number	 00000040h   
MaskBit7 . . . . . . . . . . . .	Number	 00000080h   
Q_PTR  . . . . . . . . . . . . .	Text   	 QWORD PTR
W_PTR  . . . . . . . . . . . . .	Text   	 WORD PTR
XM_PTR . . . . . . . . . . . . .	Text   	 XMMWORD PTR
YM_PTR . . . . . . . . . . . . .	Text   	 YMMWORD PTR
ZM_PTR . . . . . . . . . . . . .	Text   	 ZMMWORD PTR
__CheckAlign . . . . . . . . . .	Number	 00000000h   
__UseQ . . . . . . . . . . . . .	Number	 00000000h   
__UseX . . . . . . . . . . . . .	Number	 00000000h   
__UseY . . . . . . . . . . . . .	Number	 00000000h   
__UseZ . . . . . . . . . . . . .	Number	 00000001h   
m32BCST  . . . . . . . . . . . .	Text   	 DWORD BCST
m64BCST  . . . . . . . . . . . .	Text   	 QWORD BCST
mskAll8  . . . . . . . . . . . .	Byte	 0000000C _TEXT	
mskB0  . . . . . . . . . . . . .	Byte	 0000000D _TEXT	
mskB1  . . . . . . . . . . . . .	Byte	 0000000E _TEXT	
mskB2  . . . . . . . . . . . . .	Byte	 0000000F _TEXT	
mskB3  . . . . . . . . . . . . .	Byte	 00000010 _TEXT	
mskB4  . . . . . . . . . . . . .	Byte	 00000011 _TEXT	
mskB5  . . . . . . . . . . . . .	Byte	 00000012 _TEXT	
mskB6  . . . . . . . . . . . . .	Byte	 00000013 _TEXT	
mskB7  . . . . . . . . . . . . .	Byte	 00000014 _TEXT	
ret0 . . . . . . . . . . . . . .	DWord	 00000000 _TEXT	
ret1 . . . . . . . . . . . . . .	DWord	 00000004 _TEXT	
ret_1  . . . . . . . . . . . . .	DWord	 00000008 _TEXT	
ui512aMacros_INC . . . . . . . .	Text   	 1

	   1 Warnings
	   0 Errors
